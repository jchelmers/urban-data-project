{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caution: Scraping takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crit_violations</th>\n",
       "      <th>non_crit_violations</th>\n",
       "      <th>earliest_inspection</th>\n",
       "      <th>latest_inspection</th>\n",
       "      <th>second_latest_inspection</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>boro</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>address</th>\n",
       "      <th>num_inspections</th>\n",
       "      <th>crit_violations_recent_inspect</th>\n",
       "      <th>non_crit_violations_recent_inspect</th>\n",
       "      <th>crit_violations_train</th>\n",
       "      <th>non_crit_violations_train</th>\n",
       "      <th>num_inspections_train</th>\n",
       "      <th>average_crit_v_train</th>\n",
       "      <th>average_non_crit_v_train</th>\n",
       "      <th>time_since_last_inspection</th>\n",
       "      <th>time_since_first_inspection</th>\n",
       "      <th>crit_v_2plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30075445</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2016-02-18</td>\n",
       "      <td>2015-02-09</td>\n",
       "      <td>10462</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>1007 MORRIS PARK AVE</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>374</td>\n",
       "      <td>918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30112340</th>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014-06-05</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>11225</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>Hamburgers</td>\n",
       "      <td>469 FLATBUSH AVENUE</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>24</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30191841</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>2015-09-21</td>\n",
       "      <td>10019</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>Irish</td>\n",
       "      <td>351 WEST   57 STREET</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>253</td>\n",
       "      <td>1044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40356018</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>11224</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>American</td>\n",
       "      <td>2780 STILLWELL AVENUE</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>346</td>\n",
       "      <td>1076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40356151</th>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>2015-05-29</td>\n",
       "      <td>11369</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>American</td>\n",
       "      <td>8825 ASTORIA BOULEVARD</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>351</td>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          crit_violations  non_crit_violations earliest_inspection  \\\n",
       "30075445              8.0                  4.0          2013-08-14   \n",
       "30112340             14.0                 10.0          2014-06-05   \n",
       "30191841              4.0                  7.0          2013-07-22   \n",
       "40356018              1.0                  7.0          2013-06-05   \n",
       "40356151             13.0                  5.0          2014-04-11   \n",
       "\n",
       "         latest_inspection second_latest_inspection  zipcode       boro  \\\n",
       "30075445        2016-02-18               2015-02-09    10462      BRONX   \n",
       "30112340        2016-10-27               2016-10-03    11225   BROOKLYN   \n",
       "30191841        2016-05-31               2015-09-21    10019  MANHATTAN   \n",
       "40356018        2016-05-16               2015-06-05    11224   BROOKLYN   \n",
       "40356151        2016-05-14               2015-05-29    11369     QUEENS   \n",
       "\n",
       "             cuisine                 address  num_inspections  \\\n",
       "30075445      Bakery    1007 MORRIS PARK AVE                5   \n",
       "30112340  Hamburgers     469 FLATBUSH AVENUE                9   \n",
       "30191841       Irish    351 WEST   57 STREET                5   \n",
       "40356018    American   2780 STILLWELL AVENUE                4   \n",
       "40356151    American  8825 ASTORIA BOULEVARD                7   \n",
       "\n",
       "          crit_violations_recent_inspect  non_crit_violations_recent_inspect  \\\n",
       "30075445                               1                                   1   \n",
       "30112340                               1                                   1   \n",
       "30191841                               1                                   1   \n",
       "40356018                               1                                   1   \n",
       "40356151                               1                                   1   \n",
       "\n",
       "          crit_violations_train  non_crit_violations_train  \\\n",
       "30075445                    7.0                        3.0   \n",
       "30112340                   13.0                        9.0   \n",
       "30191841                    3.0                        6.0   \n",
       "40356018                    0.0                        6.0   \n",
       "40356151                   12.0                        4.0   \n",
       "\n",
       "          num_inspections_train  average_crit_v_train  \\\n",
       "30075445                      4                 1.750   \n",
       "30112340                      8                 1.625   \n",
       "30191841                      4                 0.750   \n",
       "40356018                      3                 0.000   \n",
       "40356151                      6                 2.000   \n",
       "\n",
       "          average_non_crit_v_train  time_since_last_inspection  \\\n",
       "30075445                  0.750000                         374   \n",
       "30112340                  1.125000                          24   \n",
       "30191841                  1.500000                         253   \n",
       "40356018                  2.000000                         346   \n",
       "40356151                  0.666667                         351   \n",
       "\n",
       "          time_since_first_inspection  crit_v_2plus  \n",
       "30075445                          918             0  \n",
       "30112340                          875             0  \n",
       "30191841                         1044             0  \n",
       "40356018                         1076             0  \n",
       "40356151                          764             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('health_inspect_cleaned.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom function to scrape Weather Underground for temperature/humidity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_CentralPark(inspection_date):\n",
    "    # Initialize dictionary to store dates we've already scraped, so that we don't repeat any\n",
    "    already_scraped = {}\n",
    "    \n",
    "    # Define the base URL for the Weather Underground historical archives\n",
    "    baseurl = 'https://www.wunderground.com/history/airport/KNYC/{}/{}/{}/DailyHistory.html' # year, month, day\n",
    "\n",
    "    # Define regular expression we'll use later\n",
    "    tag_regex = re.compile(r'<.+>([0-9.,]+)<\\/.+>')\n",
    "    \n",
    "    # Initialize lists to store 3-day temperature and humidity\n",
    "    temperature = [np.nan]*3\n",
    "    humidity = [np.nan]*3\n",
    "\n",
    "    # Scrape temperature and humidity for inspection date and up to 2 days prior\n",
    "    for i in range(0,3):\n",
    "        # Subtract appropriate number of days\n",
    "        date = pd.to_datetime(inspection_date) - np.timedelta64(i,'D')\n",
    "        \n",
    "        # Don't scrape if we've already scraped this date\n",
    "        if date in already_scraped:\n",
    "            temperature[i] = already_scraped[date][0]\n",
    "            humidity[i] = already_scraped[date][1]\n",
    "            continue\n",
    "        else:\n",
    "            # Extract year, month, and day from datetime object\n",
    "            year = pd.to_datetime(str(date)).year\n",
    "            month = pd.to_datetime(str(date)).month\n",
    "            day = pd.to_datetime(str(date)).day\n",
    "\n",
    "            # Open URL and turn into BeautifulSoup\n",
    "            r = requests.get(baseurl.format(year, month, day)).text\n",
    "            soup = BeautifulSoup(r, 'lxml')\n",
    "\n",
    "            # Find tags corresponding to average temperature and humidity\n",
    "            temperature_tag = soup.find('span', string='Mean Temperature')\n",
    "            if temperature_tag:\n",
    "                temperature_tag = temperature_tag.find_next(class_='wx-value')\n",
    "\n",
    "            humidity_tag = soup.find('span', string='Average Humidity')\n",
    "            if humidity_tag:\n",
    "                humidity_tag = humidity_tag.find_next('td')\n",
    "\n",
    "            # Use regex to extract numerical value from tags\n",
    "            # Also convert to float\n",
    "            match = re.search(tag_regex, str(temperature_tag))\n",
    "            if match:\n",
    "                temperature[i] = float(match.group(1))\n",
    "            match = re.search(tag_regex, str(humidity_tag))\n",
    "            if match:\n",
    "                humidity[i] = float(match.group(1))\n",
    "\n",
    "            # Add date and weather data to dictionary of dates we've already scraped\n",
    "            already_scraped[date] = (temperature[i], humidity[i])\n",
    "\n",
    "    # Next two lines will cause RuntimeWarning if temperature and humidity are all NaN\n",
    "    avg_temperature = np.nanmean(temperature)\n",
    "    avg_humidity = np.nanmean(humidity)\n",
    "    \n",
    "    return avg_temperature, avg_humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over rows in dataframe to add 3-day average temperature and humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for row 1 of 1854 (0% complete)\n",
      "Scraping for row 2 of 1854 (0% complete)\n",
      "Scraping for row 3 of 1854 (0% complete)\n",
      "Scraping for row 4 of 1854 (0% complete)\n",
      "Scraping for row 5 of 1854 (0% complete)\n",
      "Scraping for row 6 of 1854 (0% complete)\n",
      "Scraping for row 7 of 1854 (0% complete)\n",
      "Scraping for row 8 of 1854 (0% complete)\n",
      "Scraping for row 9 of 1854 (0% complete)\n",
      "Scraping for row 10 of 1854 (0% complete)\n",
      "Scraping for row 11 of 1854 (0% complete)\n",
      "Scraping for row 12 of 1854 (0% complete)\n",
      "Scraping for row 13 of 1854 (0% complete)\n",
      "Scraping for row 14 of 1854 (0% complete)\n",
      "Scraping for row 15 of 1854 (0% complete)\n",
      "Scraping for row 16 of 1854 (0% complete)\n",
      "Scraping for row 17 of 1854 (0% complete)\n",
      "Scraping for row 18 of 1854 (0% complete)\n",
      "Scraping for row 19 of 1854 (1% complete)\n",
      "Scraping for row 20 of 1854 (1% complete)\n",
      "Scraping for row 21 of 1854 (1% complete)\n",
      "Scraping for row 22 of 1854 (1% complete)\n",
      "Scraping for row 23 of 1854 (1% complete)\n",
      "Scraping for row 24 of 1854 (1% complete)\n",
      "Scraping for row 25 of 1854 (1% complete)\n",
      "Scraping for row 26 of 1854 (1% complete)\n",
      "Scraping for row 27 of 1854 (1% complete)\n",
      "Scraping for row 28 of 1854 (1% complete)\n",
      "Scraping for row 29 of 1854 (1% complete)\n",
      "Scraping for row 30 of 1854 (1% complete)\n",
      "Scraping for row 31 of 1854 (1% complete)\n",
      "Scraping for row 32 of 1854 (1% complete)\n",
      "Scraping for row 33 of 1854 (1% complete)\n",
      "Scraping for row 34 of 1854 (1% complete)\n",
      "Scraping for row 35 of 1854 (1% complete)\n",
      "Scraping for row 36 of 1854 (1% complete)\n",
      "Scraping for row 37 of 1854 (1% complete)\n",
      "Scraping for row 38 of 1854 (2% complete)\n",
      "Scraping for row 39 of 1854 (2% complete)\n",
      "Scraping for row 40 of 1854 (2% complete)\n",
      "Scraping for row 41 of 1854 (2% complete)\n",
      "Scraping for row 42 of 1854 (2% complete)\n",
      "Scraping for row 43 of 1854 (2% complete)\n",
      "Scraping for row 44 of 1854 (2% complete)\n",
      "Scraping for row 45 of 1854 (2% complete)\n",
      "Scraping for row 46 of 1854 (2% complete)\n",
      "Scraping for row 47 of 1854 (2% complete)\n",
      "Scraping for row 48 of 1854 (2% complete)\n",
      "Scraping for row 49 of 1854 (2% complete)\n"
     ]
    }
   ],
   "source": [
    "# Load indices of rows that are missing data from file\n",
    "with io.open('missing_weather_data.csv', 'rb') as f:\n",
    "    rows_to_scrape = f.read()\n",
    "    rows_to_scrape = rows_to_scrape.strip('[]').split(',')\n",
    "    rows_to_scrape = [int(r) for r in rows_to_scrape]\n",
    "\n",
    "to_scrape = df.iloc[rows_to_scrape]\n",
    "\n",
    "nrows = len(to_scrape)\n",
    "temp_3day = [np.nan]*nrows\n",
    "humidity_3day = [np.nan]*nrows\n",
    "inds = [np.nan]*nrows\n",
    "\n",
    "count = 0\n",
    "for index, row in to_scrape.iterrows():\n",
    "    # Keep track of progress\n",
    "    count += 1\n",
    "    print('Scraping for row {} of {} ({}% complete)'.format(count, nrows, int(((100*count)/nrows))))\n",
    "    \n",
    "    # Scrape in a try-except block and move onto next row if can't scrape successfully\n",
    "    try:\n",
    "        temp_3day[count-1], humidity_3day[count-1] = scrape_CentralPark(row['latest_inspection'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    inds[count-1] = int(index)\n",
    "\n",
    "    if count % 100 == 0: # Save intermediate results every 100 rows\n",
    "        weather_df = pd.DataFrame({'3-day temp': temp_3day, '3-day humidity': humidity_3day}, index=inds)\n",
    "        weather_df.to_csv('weather_CentralPark_partial.csv')\n",
    "\n",
    "weather_df = pd.DataFrame({'3-day temp': temp_3day, '3-day humidity': humidity_3day})\n",
    "weather_df.head()\n",
    "weather_df.to_csv('weather_CentralPark.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
