{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builds off of ML_Project_Jon but incorporates 311 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load health inspection with 311 complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violations_df = pd.read_csv('vdf_with_complaints.csv', index_col=0) # file is in GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns we don't want in our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>boro</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>crit_violations_train</th>\n",
       "      <th>non_crit_violations_train</th>\n",
       "      <th>num_inspections_train</th>\n",
       "      <th>average_crit_v_train</th>\n",
       "      <th>average_non_crit_v_train</th>\n",
       "      <th>time_since_last_inspection</th>\n",
       "      <th>time_since_first_inspection</th>\n",
       "      <th>crit_v_2plus</th>\n",
       "      <th>food_poisoning_complaints</th>\n",
       "      <th>food_establishment_complaints</th>\n",
       "      <th>electric_complaints</th>\n",
       "      <th>safety_complaints</th>\n",
       "      <th>rodent_complaints</th>\n",
       "      <th>dirty_conditions_complaints</th>\n",
       "      <th>missed_collection_complaints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40849391</th>\n",
       "      <td>10003</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>500</td>\n",
       "      <td>953</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41098999</th>\n",
       "      <td>10469</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>Hamburgers</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.50</td>\n",
       "      <td>385</td>\n",
       "      <td>946</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140992</th>\n",
       "      <td>11369</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>398</td>\n",
       "      <td>916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41317857</th>\n",
       "      <td>10017</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>Café/Coffee/Tea</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>385</td>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41382811</th>\n",
       "      <td>10469</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.80</td>\n",
       "      <td>19</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          zipcode       boro          cuisine  crit_violations_train  \\\n",
       "40849391    10003  MANHATTAN         Japanese                   10.0   \n",
       "41098999    10469      BRONX       Hamburgers                    5.0   \n",
       "41140992    11369     QUEENS       Sandwiches                    2.0   \n",
       "41317857    10017  MANHATTAN  Café/Coffee/Tea                    5.0   \n",
       "41382811    10469      BRONX        Caribbean                    9.0   \n",
       "\n",
       "          non_crit_violations_train  num_inspections_train  \\\n",
       "40849391                        7.0                      5   \n",
       "41098999                        6.0                      4   \n",
       "41140992                        5.0                      4   \n",
       "41317857                        6.0                      5   \n",
       "41382811                        9.0                      5   \n",
       "\n",
       "          average_crit_v_train  average_non_crit_v_train  \\\n",
       "40849391                  2.00                      1.40   \n",
       "41098999                  1.25                      1.50   \n",
       "41140992                  0.50                      1.25   \n",
       "41317857                  1.00                      1.20   \n",
       "41382811                  1.80                      1.80   \n",
       "\n",
       "          time_since_last_inspection  time_since_first_inspection  \\\n",
       "40849391                         500                          953   \n",
       "41098999                         385                          946   \n",
       "41140992                         398                          916   \n",
       "41317857                         385                          740   \n",
       "41382811                          19                         1008   \n",
       "\n",
       "          crit_v_2plus  food_poisoning_complaints  \\\n",
       "40849391             0                         17   \n",
       "41098999             0                          3   \n",
       "41140992             0                          0   \n",
       "41317857             0                         26   \n",
       "41382811             0                          0   \n",
       "\n",
       "          food_establishment_complaints  electric_complaints  \\\n",
       "40849391                             47                    2   \n",
       "41098999                              3                   10   \n",
       "41140992                              1                    0   \n",
       "41317857                             60                    3   \n",
       "41382811                              3                   10   \n",
       "\n",
       "          safety_complaints  rodent_complaints  dirty_conditions_complaints  \\\n",
       "40849391                  1               24.0                         33.0   \n",
       "41098999                  1                8.0                         16.0   \n",
       "41140992                  0                0.0                          0.0   \n",
       "41317857                  2               12.0                         13.0   \n",
       "41382811                  0                6.0                         31.0   \n",
       "\n",
       "          missed_collection_complaints  \n",
       "40849391                          31.0  \n",
       "41098999                           7.0  \n",
       "41140992                           0.0  \n",
       "41317857                           9.0  \n",
       "41382811                          13.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violations_df2 = violations_df.drop(['address', 'crit_violations', 'earliest_inspection',\n",
    "                                     'latest_inspection', 'second_latest_inspection',\n",
    "                                     'non_crit_violations', 'num_inspections',\n",
    "                                     'crit_violations_recent_inspect', 'non_crit_violations_recent_inspect',\n",
    "                                     'address2','latitude','longitude'],axis=1)\n",
    "violations_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: American",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c6af3fb6d6ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#violations_df2 = (violations_df2 - violations_df2.mean()) / (violations_df2.max() - violations_df2['food_poisoning_complaints'].min())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mviolations_df6\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviolations_df2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/motorrecoveryresearchlab/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mscale\u001b[0;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[1;32m    127\u001b[0m     X = check_array(X, accept_sparse='csc', copy=copy, ensure_2d=False,\n\u001b[1;32m    128\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'the scale function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                     dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/motorrecoveryresearchlab/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: American"
     ]
    }
   ],
   "source": [
    "#violations_df2 = (violations_df2 - violations_df2.mean()) / (violations_df2.max() - violations_df2['food_poisoning_complaints'].min()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical variables to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violations_df3 = pd.get_dummies(violations_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def feature_normalization(train, test):\n",
    "    \"\"\"Rescale the data so that each feature in the training set is in\n",
    "    the interval [0,1], and apply the same transformations to the test\n",
    "    set, using the statistics computed on the training set.\n",
    "\n",
    "    Args:\n",
    "        train - training set, a 2D numpy array of size (num_instances, num_features)\n",
    "        test  - test set, a 2D numpy array of size (num_instances, num_features)\n",
    "    Returns:\n",
    "        train_normalized - training set after normalization\n",
    "        test_normalized  - test set after normalization\n",
    "\n",
    "    \"\"\"\n",
    "    m = np.min(train,axis=0)\n",
    "    M = np.max(train,axis=0)\n",
    "    train_normalized = (train - m)/(M-m)\n",
    "    test_normalized = (test - m)/(M-m)\n",
    "    return train_normalized, test_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = violations_df3.drop(['crit_v_2plus'],axis=1)\n",
    "y = violations_df3['crit_v_2plus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41538262    0\n",
       "40959910    1\n",
       "50000280    1\n",
       "40402095    0\n",
       "50001610    1\n",
       "           ..\n",
       "41701184    0\n",
       "50036254    0\n",
       "41383581    1\n",
       "40513031    0\n",
       "50042048    1\n",
       "Name: crit_v_2plus, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    " \n",
    "#X_train, X_test=feature_normalization(X_train, X_test)     \n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate metrics of predicting 0 class for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.664948453608\n",
      "recall = 0.0\n",
      "precision = 0.0\n",
      "f1 = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/motorrecoveryresearchlab/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/motorrecoveryresearchlab/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pred_zero = np.zeros(len(y_test))\n",
    "print('accuracy = ' + str(sklearn.metrics.accuracy_score(y_test, pred_zero)))\n",
    "print('recall = ' + str(sklearn.metrics.recall_score(y_test, pred_zero)))\n",
    "print('precision = ' + str(sklearn.metrics.precision_score(y_test, pred_zero)))\n",
    "print('f1 = ' + str(sklearn.metrics.f1_score(y_test, pred_zero)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### w/ L2-regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.670103092784\n",
      "recall = 0.164548494983\n",
      "precision = 0.524520255864\n",
      "f1 = 0.250509164969\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(penalty = 'l2',C=1e20)\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "print('accuracy = ' + str(sklearn.metrics.accuracy_score(y_test, pred_lr)))\n",
    "print('recall = ' + str(sklearn.metrics.recall_score(y_test, pred_lr)))\n",
    "print('precision = ' + str(sklearn.metrics.precision_score(y_test, pred_lr)))\n",
    "print('f1 = ' + str(sklearn.metrics.f1_score(y_test, pred_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### w/ L1-regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.67032720753\n",
      "recall = 0.164548494983\n",
      "precision = 0.525641025641\n",
      "f1 = 0.250636780438\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(penalty = 'l1',C=1e20)\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "print('accuracy = ' + str(sklearn.metrics.accuracy_score(y_test, pred_lr)))\n",
    "print('recall = ' + str(sklearn.metrics.recall_score(y_test, pred_lr)))\n",
    "print('precision = ' + str(sklearn.metrics.precision_score(y_test, pred_lr)))\n",
    "print('f1 = ' + str(sklearn.metrics.f1_score(y_test, pred_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### w/ fit prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.656432093232\n",
      "recall = 0.0615384615385\n",
      "precision = 0.414414414414\n",
      "f1 = 0.107163657542\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB(alpha=1,fit_prior=True)\n",
    "nb.fit(X_train, y_train)\n",
    "pred_nb = nb.predict(X_test)\n",
    "print('accuracy = ' + str(sklearn.metrics.accuracy_score(y_test, pred_nb)))\n",
    "print('recall = ' + str(sklearn.metrics.recall_score(y_test, pred_nb)))\n",
    "print('precision = ' + str(sklearn.metrics.precision_score(y_test, pred_nb)))\n",
    "print('f1 = ' + str(sklearn.metrics.f1_score(y_test, pred_nb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### w/ uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.533393097266\n",
      "recall = 0.640133779264\n",
      "precision = 0.382646941224\n",
      "f1 = 0.478978978979\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB(alpha=1,fit_prior=False)\n",
    "nb.fit(X_train, y_train)\n",
    "pred_nb = nb.predict(X_test)\n",
    "print('accuracy = ' + str(sklearn.metrics.accuracy_score(y_test, pred_nb)))\n",
    "print('recall = ' + str(sklearn.metrics.recall_score(y_test, pred_nb)))\n",
    "print('precision = ' + str(sklearn.metrics.precision_score(y_test, pred_nb)))\n",
    "print('f1 = ' + str(sklearn.metrics.f1_score(y_test, pred_nb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.650156880323\n",
      "recall = 0.204682274247\n",
      "precision = 0.451327433628\n",
      "f1 = 0.281638288081\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "print('accuracy = ' + str(sklearn.metrics.accuracy_score(y_test, pred_rf)))\n",
    "print('recall = ' + str(sklearn.metrics.recall_score(y_test, pred_rf)))\n",
    "print('precision = ' + str(sklearn.metrics.precision_score(y_test, pred_rf)))\n",
    "print('f1 = ' + str(sklearn.metrics.f1_score(y_test, pred_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.65307037203\n",
      "recall = 0.197993311037\n",
      "precision = 0.458914728682\n",
      "f1 = 0.276635514019\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=20)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "print('accuracy = ' + str(sklearn.metrics.accuracy_score(y_test, pred_rf)))\n",
    "print('recall = ' + str(sklearn.metrics.recall_score(y_test, pred_rf)))\n",
    "print('precision = ' + str(sklearn.metrics.precision_score(y_test, pred_rf)))\n",
    "print('f1 = ' + str(sklearn.metrics.f1_score(y_test, pred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
