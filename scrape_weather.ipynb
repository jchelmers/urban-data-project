{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scrape_weather import scrape_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crit_violations</th>\n",
       "      <th>non_crit_violations</th>\n",
       "      <th>earliest_inspection</th>\n",
       "      <th>latest_inspection</th>\n",
       "      <th>second_latest_inspection</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>boro</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>address</th>\n",
       "      <th>num_inspections</th>\n",
       "      <th>crit_violations_recent_inspect</th>\n",
       "      <th>non_crit_violations_recent_inspect</th>\n",
       "      <th>crit_violations_train</th>\n",
       "      <th>non_crit_violations_train</th>\n",
       "      <th>num_inspections_train</th>\n",
       "      <th>average_crit_v_train</th>\n",
       "      <th>average_non_crit_v_train</th>\n",
       "      <th>time_since_last_inspection</th>\n",
       "      <th>time_since_first_inspection</th>\n",
       "      <th>crit_v_2plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30075445</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2016-02-18</td>\n",
       "      <td>2015-02-09</td>\n",
       "      <td>10462</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>1007 MORRIS PARK AVE</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>374</td>\n",
       "      <td>918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30112340</th>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014-06-05</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>11225</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>Hamburgers</td>\n",
       "      <td>469 FLATBUSH AVENUE</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>24</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30191841</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>2015-09-21</td>\n",
       "      <td>10019</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>Irish</td>\n",
       "      <td>351 WEST   57 STREET</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>253</td>\n",
       "      <td>1044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40356018</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>11224</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>American</td>\n",
       "      <td>2780 STILLWELL AVENUE</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>346</td>\n",
       "      <td>1076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40356151</th>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>2015-05-29</td>\n",
       "      <td>11369</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>American</td>\n",
       "      <td>8825 ASTORIA BOULEVARD</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>351</td>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          crit_violations  non_crit_violations earliest_inspection  \\\n",
       "30075445              8.0                  4.0          2013-08-14   \n",
       "30112340             14.0                 10.0          2014-06-05   \n",
       "30191841              4.0                  7.0          2013-07-22   \n",
       "40356018              1.0                  7.0          2013-06-05   \n",
       "40356151             13.0                  5.0          2014-04-11   \n",
       "\n",
       "         latest_inspection second_latest_inspection  zipcode       boro  \\\n",
       "30075445        2016-02-18               2015-02-09    10462      BRONX   \n",
       "30112340        2016-10-27               2016-10-03    11225   BROOKLYN   \n",
       "30191841        2016-05-31               2015-09-21    10019  MANHATTAN   \n",
       "40356018        2016-05-16               2015-06-05    11224   BROOKLYN   \n",
       "40356151        2016-05-14               2015-05-29    11369     QUEENS   \n",
       "\n",
       "             cuisine                 address  num_inspections  \\\n",
       "30075445      Bakery    1007 MORRIS PARK AVE                5   \n",
       "30112340  Hamburgers     469 FLATBUSH AVENUE                9   \n",
       "30191841       Irish    351 WEST   57 STREET                5   \n",
       "40356018    American   2780 STILLWELL AVENUE                4   \n",
       "40356151    American  8825 ASTORIA BOULEVARD                7   \n",
       "\n",
       "          crit_violations_recent_inspect  non_crit_violations_recent_inspect  \\\n",
       "30075445                               1                                   1   \n",
       "30112340                               1                                   1   \n",
       "30191841                               1                                   1   \n",
       "40356018                               1                                   1   \n",
       "40356151                               1                                   1   \n",
       "\n",
       "          crit_violations_train  non_crit_violations_train  \\\n",
       "30075445                    7.0                        3.0   \n",
       "30112340                   13.0                        9.0   \n",
       "30191841                    3.0                        6.0   \n",
       "40356018                    0.0                        6.0   \n",
       "40356151                   12.0                        4.0   \n",
       "\n",
       "          num_inspections_train  average_crit_v_train  \\\n",
       "30075445                      4                 1.750   \n",
       "30112340                      8                 1.625   \n",
       "30191841                      4                 0.750   \n",
       "40356018                      3                 0.000   \n",
       "40356151                      6                 2.000   \n",
       "\n",
       "          average_non_crit_v_train  time_since_last_inspection  \\\n",
       "30075445                  0.750000                         374   \n",
       "30112340                  1.125000                          24   \n",
       "30191841                  1.500000                         253   \n",
       "40356018                  2.000000                         346   \n",
       "40356151                  0.666667                         351   \n",
       "\n",
       "          time_since_first_inspection  crit_v_2plus  \n",
       "30075445                          918             0  \n",
       "30112340                          875             0  \n",
       "30191841                         1044             0  \n",
       "40356018                         1076             0  \n",
       "40356151                          764             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../health_inspect_cleaned.csv', index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom function to scrape Weather Underground for temperature/humidity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_weather(zipcode, inspection_date):\n",
    "    # Define the base URL for the Weather Underground historical archives\n",
    "    baseurl = 'https://www.wunderground.com/history/zipcode/{}/{}/{}/{}/DailyHistory.html' # zipcode, year, month, day\n",
    "\n",
    "    # Define regular expression we'll use later\n",
    "    tag_regex = re.compile(r'<.+>([0-9.,]+)<\\/.+>')\n",
    "    \n",
    "    # Initialize lists to store 3-day temperature and humidity\n",
    "    temperature = [np.nan]*3\n",
    "    humidity = [np.nan]*3\n",
    "\n",
    "    # Scrape temperature and humidity for inspection date and up to 2 days prior\n",
    "    for i in range(0,3):\n",
    "        # Subtract appropriate number of days\n",
    "        date = pd.to_datetime(inspection_date) - np.timedelta64(i,'D')\n",
    "\n",
    "        # Extract year, month, and day from datetime object\n",
    "        year = pd.to_datetime(str(date)).year\n",
    "        month = pd.to_datetime(str(date)).month\n",
    "        day = pd.to_datetime(str(date)).day\n",
    "\n",
    "        # Open URL and turn into BeautifulSoup\n",
    "        r = requests.get(baseurl.format(zipcode, year, month, day)).text\n",
    "        soup = BeautifulSoup(r, 'lxml')\n",
    "\n",
    "        # Find tags corresponding to average temperature and humidity\n",
    "        temperature_tag = soup.find('span', string='Mean Temperature')\n",
    "        if temperature_tag:\n",
    "            temperature_tag = temperature_tag.find_next(class_='wx-value')\n",
    "        \n",
    "        humidity_tag = soup.find('span', string='Average Humidity')\n",
    "        if humidity_tag:\n",
    "            humidity_tag = humidity_tag.find_next('td')\n",
    "\n",
    "        # Use regex to extract numerical value from tags\n",
    "        # Also convert to float\n",
    "        match = re.search(tag_regex, str(temperature_tag))\n",
    "        if match:\n",
    "            temperature[i] = float(match.group(1))\n",
    "        match = re.search(tag_regex, str(humidity_tag))\n",
    "        if match:\n",
    "            humidity[i] = float(match.group(1))\n",
    "\n",
    "    # Next two lines will cause RuntimeWarning if temperature and humidity are all NaN\n",
    "    avg_temperature = np.nanmean(temperature)\n",
    "    avg_humidity = np.nanmean(humidity)\n",
    "    \n",
    "    return avg_temperature, avg_humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over rows in dataframe to add 3-day average temperature and humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for row 1 of 22330 (0% complete)\n",
      "Scraping for row 2 of 22330 (0% complete)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julie\\Anaconda2\\envs\\py35\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:703: RuntimeWarning: Mean of empty slice\n",
      "  warnings.warn(\"Mean of empty slice\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for row 3 of 22330 (0% complete)\n",
      "Scraping for row 4 of 22330 (0% complete)\n",
      "Scraping for row 5 of 22330 (0% complete)\n",
      "Scraping for row 6 of 22330 (0% complete)\n",
      "Scraping for row 7 of 22330 (0% complete)\n",
      "Scraping for row 8 of 22330 (0% complete)\n",
      "Scraping for row 9 of 22330 (0% complete)\n",
      "Scraping for row 10 of 22330 (0% complete)\n",
      "Scraping for row 11 of 22330 (0% complete)\n",
      "Scraping for row 12 of 22330 (0% complete)\n",
      "Scraping for row 13 of 22330 (0% complete)\n",
      "Scraping for row 14 of 22330 (0% complete)\n",
      "Scraping for row 15 of 22330 (0% complete)\n",
      "Scraping for row 16 of 22330 (0% complete)\n"
     ]
    }
   ],
   "source": [
    "nrows = len(df)\n",
    "temp_3day = [np.nan]*nrows\n",
    "humidity_3day = [np.nan]*nrows\n",
    "\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    # Keep track of progress\n",
    "    count += 1\n",
    "    print('Scraping for row {} of {} ({}% complete)'.format(count, nrows, count//nrows))\n",
    "    \n",
    "    # Scrape in a try-except block and move onto next row if can't scrape successfully\n",
    "    try:\n",
    "        temp_3day[count-1], humidity_3day[count-1] = scrape_weather(row['zipcode'], row['latest_inspection'])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    if count % 100 == 0:\n",
    "        weather_df = pd.DataFrame({'3-day temp': temp_3day, '3-day humidity': humidity_3day})\n",
    "        weather_df.to_csv('../../weather_data.csv')\n",
    "\n",
    "weather_df = pd.DataFrame({'3-day temp': temp_3day, '3-day humidity': humidity_3day})\n",
    "weather_df.head()\n",
    "weather_df.to_csv('../../weather_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
